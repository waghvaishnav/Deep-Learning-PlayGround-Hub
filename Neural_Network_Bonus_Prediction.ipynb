{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwtHR4ucmhy8LGcguiwgmV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waghvaishnav/Deep-Learning-PlayGround-Hub/blob/main/Neural_Network_Bonus_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Employee Bonus Prediction"
      ],
      "metadata": {
        "id": "b4zwmg02_1Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing data\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "y6Xw-E3gALSY",
        "outputId": "d964b7fe-28d0-4fab-8022-88b772da7448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c07393d6-692b-45f3-8aef-2e7f94636db7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c07393d6-692b-45f3-8aef-2e7f94636db7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bonus prediction nn.csv to bonus prediction nn.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bonus prediction nn.csv': b'employee_id,performance,years_of_experience,projects_completed,bonus\\r\\nEMP_001,7,1,3,116\\r\\nEMP_002,4,8,10,136\\r\\nEMP_003,8,4,5,150\\r\\nEMP_004,5,4,7,118\\r\\nEMP_005,7,5,6,146\\r\\nEMP_006,10,8,9,206\\r\\nEMP_007,3,5,8,102\\r\\nEMP_008,7,8,11,174\\r\\nEMP_009,8,10,12,200\\r\\nEMP_010,5,1,4,94\\r\\nEMP_011,4,10,12,152\\r\\nEMP_012,8,9,11,192\\r\\nEMP_013,8,6,8,168\\r\\nEMP_014,3,3,6,86\\r\\nEMP_015,6,8,9,158\\r\\nEMP_016,5,9,11,156\\r\\nEMP_017,2,6,7,94\\r\\nEMP_018,8,7,8,174\\r\\nEMP_019,6,1,4,106\\r\\nEMP_020,2,5,6,86\\r\\nEMP_021,5,5,6,122\\r\\nEMP_022,1,10,13,118\\r\\nEMP_023,10,4,6,176\\r\\nEMP_024,6,6,7,142\\r\\nEMP_025,9,7,10,190\\r\\nEMP_026,1,9,10,106\\r\\nEMP_027,10,1,2,150\\r\\nEMP_028,3,6,8,108\\r\\nEMP_029,7,7,8,162\\r\\nEMP_030,4,3,6,98\\r\\nEMP_031,9,8,9,194\\r\\nEMP_032,3,5,7,100\\r\\nEMP_033,5,9,11,156\\r\\nEMP_034,3,5,8,102\\r\\nEMP_035,7,9,11,180\\r\\nEMP_036,5,10,11,162\\r\\nEMP_037,9,4,6,164\\r\\nEMP_038,7,9,12,182\\r\\nEMP_039,2,5,7,88\\r\\nEMP_040,4,10,12,152\\r\\nEMP_041,9,9,11,204\\r\\nEMP_042,2,3,6,74\\r\\nEMP_043,10,4,6,176\\r\\nEMP_044,9,9,11,204\\r\\nEMP_045,10,10,11,222\\r\\nEMP_046,5,6,9,134\\r\\nEMP_047,2,2,4,64\\r\\nEMP_048,4,7,10,130\\r\\nEMP_049,7,2,4,124\\r\\nEMP_050,8,2,4,136\\r\\nEMP_051,3,1,3,68\\r\\nEMP_052,1,3,4,58\\r\\nEMP_053,4,6,7,118\\r\\nEMP_054,2,8,9,110\\r\\nEMP_055,8,9,12,194\\r\\nEMP_056,4,7,10,130\\r\\nEMP_057,2,4,5,78\\r\\nEMP_058,6,6,9,146\\r\\nEMP_059,6,5,7,136\\r\\nEMP_060,10,8,10,208\\r\\nEMP_061,4,1,3,80\\r\\nEMP_062,6,1,2,102\\r\\nEMP_063,2,6,9,98\\r\\nEMP_064,10,10,11,222\\r\\nEMP_065,2,2,5,66\\r\\nEMP_066,10,5,7,184\\r\\nEMP_067,4,1,2,78\\r\\nEMP_068,8,7,10,178\\r\\nEMP_069,7,1,4,118\\r\\nEMP_070,9,4,6,164\\r\\nEMP_071,8,9,10,190\\r\\nEMP_072,5,1,2,90\\r\\nEMP_073,2,4,5,78\\r\\nEMP_074,5,6,8,132\\r\\nEMP_075,8,6,7,166\\r\\nEMP_076,10,8,10,208\\r\\nEMP_077,9,1,3,140\\r\\nEMP_078,9,7,9,188\\r\\nEMP_079,1,1,4,46\\r\\nEMP_080,9,7,8,186\\r\\nEMP_081,7,3,4,130\\r\\nEMP_082,9,8,10,196\\r\\nEMP_083,8,3,5,144\\r\\nEMP_084,1,1,2,42\\r\\nEMP_085,8,8,10,184\\r\\nEMP_086,8,3,4,142\\r\\nEMP_087,3,2,5,78\\r\\nEMP_088,1,1,3,44\\r\\nEMP_089,8,3,4,142\\r\\nEMP_090,3,2,4,76\\r\\nEMP_091,3,2,3,74\\r\\nEMP_092,1,6,7,82\\r\\nEMP_093,5,1,3,92\\r\\nEMP_094,10,2,5,162\\r\\nEMP_095,7,6,7,154\\r\\nEMP_096,10,3,4,166\\r\\nEMP_097,9,4,5,162\\r\\nEMP_098,7,1,4,118\\r\\nEMP_099,9,8,11,198\\r\\nEMP_100,8,7,9,176\\r\\nEMP_101,2,7,10,106\\r\\nEMP_102,1,3,5,60\\r\\nEMP_103,7,10,12,188\\r\\nEMP_104,7,10,13,190\\r\\nEMP_105,8,3,5,144\\r\\nEMP_106,5,2,5,102\\r\\nEMP_107,3,1,3,68\\r\\nEMP_108,8,7,10,178\\r\\nEMP_109,6,7,10,154\\r\\nEMP_110,3,2,4,76\\r\\nEMP_111,1,7,8,90\\r\\nEMP_112,3,8,10,124\\r\\nEMP_113,5,1,4,94\\r\\nEMP_114,3,9,10,130\\r\\nEMP_115,1,7,9,92\\r\\nEMP_116,5,3,5,108\\r\\nEMP_117,10,8,10,208\\r\\nEMP_118,7,7,8,162\\r\\nEMP_119,7,8,11,174\\r\\nEMP_120,9,6,8,180\\r\\nEMP_121,10,9,11,216\\r\\nEMP_122,10,5,7,184\\r\\nEMP_123,3,3,5,84\\r\\nEMP_124,7,3,5,132\\r\\nEMP_125,1,1,4,46\\r\\nEMP_126,4,8,11,138\\r\\nEMP_127,4,2,4,88\\r\\nEMP_128,5,3,4,106\\r\\nEMP_129,7,8,11,174\\r\\nEMP_130,7,8,9,170\\r\\nEMP_131,4,4,7,106\\r\\nEMP_132,7,4,6,140\\r\\nEMP_133,3,5,8,102\\r\\nEMP_134,6,6,8,144\\r\\nEMP_135,2,5,8,90\\r\\nEMP_136,10,7,9,200\\r\\nEMP_137,9,2,4,148\\r\\nEMP_138,5,7,9,140\\r\\nEMP_139,6,10,12,176\\r\\nEMP_140,4,7,8,126\\r\\nEMP_141,10,1,3,152\\r\\nEMP_142,7,7,8,162\\r\\nEMP_143,9,5,6,170\\r\\nEMP_144,7,3,5,132\\r\\nEMP_145,1,3,4,58\\r\\nEMP_146,1,4,7,70\\r\\nEMP_147,9,2,4,148\\r\\nEMP_148,9,2,3,146\\r\\nEMP_149,4,1,3,80\\r\\nEMP_150,9,5,7,172\\r\\nEMP_151,3,4,6,92\\r\\nEMP_152,7,10,11,186\\r\\nEMP_153,6,2,5,114\\r\\nEMP_154,8,3,6,146\\r\\nEMP_155,9,7,8,186\\r\\nEMP_156,5,7,9,140\\r\\nEMP_157,1,4,5,66\\r\\nEMP_158,3,5,6,98\\r\\nEMP_159,10,5,6,182\\r\\nEMP_160,8,6,8,168\\r\\nEMP_161,6,9,10,166\\r\\nEMP_162,8,2,4,136\\r\\nEMP_163,9,5,6,170\\r\\nEMP_164,4,3,6,98\\r\\nEMP_165,1,4,5,66\\r\\nEMP_166,1,10,11,114\\r\\nEMP_167,10,6,9,194\\r\\nEMP_168,4,8,10,136\\r\\nEMP_169,7,1,3,116\\r\\nEMP_170,2,10,11,126\\r\\nEMP_171,3,8,11,126\\r\\nEMP_172,1,7,9,92\\r\\nEMP_173,5,1,2,90\\r\\nEMP_174,1,2,5,54\\r\\nEMP_175,8,3,5,144\\r\\nEMP_176,1,1,3,44\\r\\nEMP_177,1,9,12,110\\r\\nEMP_178,2,8,11,114\\r\\nEMP_179,2,2,5,66\\r\\nEMP_180,6,9,12,170\\r\\nEMP_181,7,7,8,162\\r\\nEMP_182,5,9,12,158\\r\\nEMP_183,1,6,8,84\\r\\nEMP_184,1,6,8,84\\r\\nEMP_185,3,4,5,90\\r\\nEMP_186,2,10,12,128\\r\\nEMP_187,5,10,12,164\\r\\nEMP_188,10,2,5,162\\r\\nEMP_189,6,7,9,152\\r\\nEMP_190,7,5,6,146\\r\\nEMP_191,4,6,9,122\\r\\nEMP_192,7,2,5,126\\r\\nEMP_193,8,5,6,158\\r\\nEMP_194,1,10,13,118\\r\\nEMP_195,6,4,7,130\\r\\nEMP_196,8,9,10,190\\r\\nEMP_197,5,6,9,134\\r\\nEMP_198,4,2,3,86\\r\\nEMP_199,2,1,2,54\\r\\nEMP_200,6,5,7,136\\r\\nEMP_201,6,9,11,168\\r\\nEMP_202,1,6,9,86\\r\\nEMP_203,9,10,13,214\\r\\nEMP_204,6,7,8,150\\r\\nEMP_205,3,5,8,102\\r\\nEMP_206,4,10,11,150\\r\\nEMP_207,4,6,7,118\\r\\nEMP_208,3,5,8,102\\r\\nEMP_209,10,9,10,214\\r\\nEMP_210,3,6,8,108\\r\\nEMP_211,3,8,11,126\\r\\nEMP_212,4,2,4,88\\r\\nEMP_213,7,9,12,182\\r\\nEMP_214,4,5,6,110\\r\\nEMP_215,9,7,10,190\\r\\nEMP_216,1,10,12,116\\r\\nEMP_217,8,1,2,126\\r\\nEMP_218,7,10,13,190\\r\\nEMP_219,2,5,8,90\\r\\nEMP_220,8,10,13,202\\r\\nEMP_221,1,2,4,52\\r\\nEMP_222,9,6,8,180\\r\\nEMP_223,9,1,4,142\\r\\nEMP_224,2,3,4,70\\r\\nEMP_225,7,5,6,146\\r\\nEMP_226,10,4,6,176\\r\\nEMP_227,3,3,4,82\\r\\nEMP_228,7,10,12,188\\r\\nEMP_229,10,5,8,186\\r\\nEMP_230,9,8,10,196\\r\\nEMP_231,4,4,6,104\\r\\nEMP_232,1,1,4,46\\r\\nEMP_233,2,7,8,102\\r\\nEMP_234,1,8,10,100\\r\\nEMP_235,5,3,5,108\\r\\nEMP_236,5,6,9,134\\r\\nEMP_237,7,2,3,122\\r\\nEMP_238,9,7,9,188\\r\\nEMP_239,9,8,11,198\\r\\nEMP_240,3,6,8,108\\r\\nEMP_241,3,6,9,110\\r\\nEMP_242,3,5,6,98\\r\\nEMP_243,4,8,9,134\\r\\nEMP_244,8,1,2,126\\r\\nEMP_245,6,10,11,174\\r\\nEMP_246,8,4,6,152\\r\\nEMP_247,1,4,6,68\\r\\nEMP_248,8,3,4,142\\r\\nEMP_249,4,3,4,94\\r\\nEMP_250,1,4,5,66\\r\\nEMP_251,8,1,3,128\\r\\nEMP_252,4,2,3,86\\r\\nEMP_253,6,9,10,166\\r\\nEMP_254,8,10,11,198\\r\\nEMP_255,4,2,5,90\\r\\nEMP_256,3,5,6,98\\r\\nEMP_257,9,9,12,206\\r\\nEMP_258,3,9,12,134\\r\\nEMP_259,9,8,9,194\\r\\nEMP_260,2,1,4,58\\r\\nEMP_261,2,1,2,54\\r\\nEMP_262,2,9,11,120\\r\\nEMP_263,6,8,10,160\\r\\nEMP_264,3,10,12,140\\r\\nEMP_265,9,9,11,204\\r\\nEMP_266,4,7,10,130\\r\\nEMP_267,1,3,4,58\\r\\nEMP_268,4,3,4,94\\r\\nEMP_269,1,2,3,50\\r\\nEMP_270,5,5,7,124\\r\\nEMP_271,4,3,5,96\\r\\nEMP_272,8,6,7,166\\r\\nEMP_273,8,2,4,136\\r\\nEMP_274,7,3,4,130\\r\\nEMP_275,3,5,6,98\\r\\nEMP_276,1,1,2,42\\r\\nEMP_277,1,1,2,42\\r\\nEMP_278,3,10,11,138\\r\\nEMP_279,6,9,10,166\\r\\nEMP_280,7,7,8,162\\r\\nEMP_281,6,1,3,104\\r\\nEMP_282,6,8,9,158\\r\\nEMP_283,6,3,4,118\\r\\nEMP_284,3,8,10,124\\r\\nEMP_285,6,5,7,136\\r\\nEMP_286,8,1,3,128\\r\\nEMP_287,2,7,8,102\\r\\nEMP_288,5,5,8,126\\r\\nEMP_289,1,6,9,86\\r\\nEMP_290,1,6,8,84\\r\\nEMP_291,5,8,11,150\\r\\nEMP_292,3,9,11,132\\r\\nEMP_293,4,2,3,86\\r\\nEMP_294,3,9,12,134\\r\\nEMP_295,1,10,11,114\\r\\nEMP_296,1,9,12,110\\r\\nEMP_297,5,10,11,162\\r\\nEMP_298,6,10,13,178\\r\\nEMP_299,3,7,8,114\\r\\nEMP_300,9,1,2,138\\r\\nEMP_301,5,7,10,142\\r\\nEMP_302,8,10,11,198\\r\\nEMP_303,1,5,6,74\\r\\nEMP_304,5,6,7,130\\r\\nEMP_305,3,10,13,142\\r\\nEMP_306,1,7,10,94\\r\\nEMP_307,4,5,6,110\\r\\nEMP_308,5,7,8,138\\r\\nEMP_309,7,9,12,182\\r\\nEMP_310,1,3,6,62\\r\\nEMP_311,3,8,9,122\\r\\nEMP_312,2,2,3,62\\r\\nEMP_313,9,7,8,186\\r\\nEMP_314,10,2,4,160\\r\\nEMP_315,6,4,7,130\\r\\nEMP_316,10,7,9,200\\r\\nEMP_317,3,3,6,86\\r\\nEMP_318,8,2,5,138\\r\\nEMP_319,8,10,13,202\\r\\nEMP_320,2,7,10,106\\r\\nEMP_321,6,1,4,106\\r\\nEMP_322,7,8,11,174\\r\\nEMP_323,2,3,6,74\\r\\nEMP_324,10,2,4,160\\r\\nEMP_325,2,3,4,70\\r\\nEMP_326,10,5,6,182\\r\\nEMP_327,1,8,10,100\\r\\nEMP_328,8,10,12,200\\r\\nEMP_329,1,7,9,92\\r\\nEMP_330,9,7,9,188\\r\\nEMP_331,6,7,10,154\\r\\nEMP_332,7,8,9,170\\r\\nEMP_333,10,1,4,154\\r\\nEMP_334,7,4,5,138\\r\\nEMP_335,10,6,7,190\\r\\nEMP_336,3,9,11,132\\r\\nEMP_337,2,2,5,66\\r\\nEMP_338,9,1,3,140\\r\\nEMP_339,8,10,13,202\\r\\nEMP_340,10,2,3,158\\r\\nEMP_341,7,7,9,164\\r\\nEMP_342,9,3,5,156\\r\\nEMP_343,4,10,11,150\\r\\nEMP_344,4,2,3,86\\r\\nEMP_345,1,7,8,90\\r\\nEMP_346,8,2,4,136\\r\\nEMP_347,3,3,6,86\\r\\nEMP_348,7,7,9,164\\r\\nEMP_349,2,4,7,82\\r\\nEMP_350,2,1,3,56\\r\\nEMP_351,7,5,7,148\\r\\nEMP_352,6,9,10,166\\r\\nEMP_353,3,8,11,126\\r\\nEMP_354,9,9,11,204\\r\\nEMP_355,10,10,12,224\\r\\nEMP_356,6,9,10,166\\r\\nEMP_357,10,7,8,198\\r\\nEMP_358,10,4,7,178\\r\\nEMP_359,6,5,7,136\\r\\nEMP_360,1,1,4,46\\r\\nEMP_361,4,1,3,80\\r\\nEMP_362,10,3,6,170\\r\\nEMP_363,6,8,9,158\\r\\nEMP_364,6,2,4,112\\r\\nEMP_365,5,4,7,118\\r\\nEMP_366,1,2,3,50\\r\\nEMP_367,8,5,6,158\\r\\nEMP_368,5,9,12,158\\r\\nEMP_369,5,1,3,92\\r\\nEMP_370,7,5,7,148\\r\\nEMP_371,4,9,10,142\\r\\nEMP_372,6,1,3,104\\r\\nEMP_373,4,9,11,144\\r\\nEMP_374,3,8,10,124\\r\\nEMP_375,7,4,5,138\\r\\nEMP_376,8,10,13,202\\r\\nEMP_377,4,5,7,112\\r\\nEMP_378,2,5,6,86\\r\\nEMP_379,10,6,7,190\\r\\nEMP_380,3,7,10,118\\r\\nEMP_381,1,8,10,100\\r\\nEMP_382,8,8,10,184\\r\\nEMP_383,3,2,5,78\\r\\nEMP_384,10,9,12,218\\r\\nEMP_385,7,7,8,162\\r\\nEMP_386,10,4,5,174\\r\\nEMP_387,5,4,7,118\\r\\nEMP_388,10,8,10,208\\r\\nEMP_389,5,4,5,114\\r\\nEMP_390,7,6,7,154\\r\\nEMP_391,9,5,7,172\\r\\nEMP_392,5,3,4,106\\r\\nEMP_393,1,10,12,116\\r\\nEMP_394,10,2,4,160\\r\\nEMP_395,10,9,11,216\\r\\nEMP_396,1,10,13,118\\r\\nEMP_397,2,9,12,122\\r\\nEMP_398,6,1,4,106\\r\\nEMP_399,9,10,12,212\\r\\nEMP_400,8,3,5,144\\r\\nEMP_401,5,8,11,150\\r\\nEMP_402,1,6,7,82\\r\\nEMP_403,7,5,7,148\\r\\nEMP_404,5,5,6,122\\r\\nEMP_405,6,6,7,142\\r\\nEMP_406,7,7,9,164\\r\\nEMP_407,3,1,3,68\\r\\nEMP_408,10,9,10,214\\r\\nEMP_409,3,3,4,82\\r\\nEMP_410,5,4,7,118\\r\\nEMP_411,6,10,13,178\\r\\nEMP_412,9,1,3,140\\r\\nEMP_413,5,10,13,166\\r\\nEMP_414,1,3,6,62\\r\\nEMP_415,4,2,5,90\\r\\nEMP_416,5,2,5,102\\r\\nEMP_417,10,1,2,150\\r\\nEMP_418,10,8,10,208\\r\\nEMP_419,5,3,6,110\\r\\nEMP_420,7,3,4,130\\r\\nEMP_421,4,6,7,118\\r\\nEMP_422,1,8,9,98\\r\\nEMP_423,5,9,12,158\\r\\nEMP_424,7,9,12,182\\r\\nEMP_425,10,4,6,176\\r\\nEMP_426,10,5,8,186\\r\\nEMP_427,6,2,5,114\\r\\nEMP_428,5,9,10,154\\r\\nEMP_429,4,8,10,136\\r\\nEMP_430,2,3,6,74\\r\\nEMP_431,4,9,12,146\\r\\nEMP_432,10,3,4,166\\r\\nEMP_433,10,9,10,214\\r\\nEMP_434,3,2,5,78\\r\\nEMP_435,10,10,12,224\\r\\nEMP_436,1,9,11,108\\r\\nEMP_437,8,8,9,182\\r\\nEMP_438,5,9,10,154\\r\\nEMP_439,4,5,8,114\\r\\nEMP_440,8,2,3,134\\r\\nEMP_441,7,8,11,174\\r\\nEMP_442,2,6,8,96\\r\\nEMP_443,1,8,10,100\\r\\nEMP_444,4,5,8,114\\r\\nEMP_445,8,10,11,198\\r\\nEMP_446,2,2,4,64\\r\\nEMP_447,3,6,7,106\\r\\nEMP_448,1,5,7,76\\r\\nEMP_449,1,5,8,78\\r\\nEMP_450,3,1,4,70\\r\\nEMP_451,5,2,5,102\\r\\nEMP_452,3,8,10,124\\r\\nEMP_453,1,3,4,58\\r\\nEMP_454,1,10,11,114\\r\\nEMP_455,8,3,4,142\\r\\nEMP_456,10,8,10,208\\r\\nEMP_457,2,8,10,112\\r\\nEMP_458,3,2,4,76\\r\\nEMP_459,2,8,10,112\\r\\nEMP_460,3,1,3,68\\r\\nEMP_461,7,6,7,154\\r\\nEMP_462,1,8,10,100\\r\\nEMP_463,10,3,5,168\\r\\nEMP_464,8,8,9,182\\r\\nEMP_465,10,1,3,152\\r\\nEMP_466,10,9,10,214\\r\\nEMP_467,10,9,10,214\\r\\nEMP_468,2,5,8,90\\r\\nEMP_469,3,10,13,142\\r\\nEMP_470,9,4,7,166\\r\\nEMP_471,7,6,9,158\\r\\nEMP_472,4,7,9,128\\r\\nEMP_473,10,5,8,186\\r\\nEMP_474,5,10,11,162\\r\\nEMP_475,2,9,11,120\\r\\nEMP_476,8,3,6,146\\r\\nEMP_477,4,7,8,126\\r\\nEMP_478,9,10,12,212\\r\\nEMP_479,5,10,12,164\\r\\nEMP_480,9,5,8,174\\r\\nEMP_481,4,7,9,128\\r\\nEMP_482,10,2,3,158\\r\\nEMP_483,5,4,6,116\\r\\nEMP_484,9,2,3,146\\r\\nEMP_485,8,7,9,176\\r\\nEMP_486,3,2,5,78\\r\\nEMP_487,1,1,2,42\\r\\nEMP_488,3,9,11,132\\r\\nEMP_489,4,1,3,80\\r\\nEMP_490,2,8,10,112\\r\\nEMP_491,1,2,3,50\\r\\nEMP_492,7,8,9,170\\r\\nEMP_493,8,3,4,142\\r\\nEMP_494,7,6,9,158\\r\\nEMP_495,5,3,6,110\\r\\nEMP_496,1,7,8,90\\r\\nEMP_497,7,10,12,188\\r\\nEMP_498,7,9,12,182\\r\\nEMP_499,9,2,3,146\\r\\nEMP_500,3,5,7,100\\r\\nEMP_501,9,6,9,182\\r\\nEMP_502,1,4,6,68\\r\\nEMP_503,1,4,6,68\\r\\nEMP_504,4,4,6,104\\r\\nEMP_505,9,2,4,148\\r\\nEMP_506,6,4,7,130\\r\\nEMP_507,3,1,4,70\\r\\nEMP_508,1,6,9,86\\r\\nEMP_509,4,1,2,78\\r\\nEMP_510,9,10,13,214\\r\\nEMP_511,3,6,8,108\\r\\nEMP_512,9,1,4,142\\r\\nEMP_513,7,6,8,156\\r\\nEMP_514,4,10,11,150\\r\\nEMP_515,3,8,10,124\\r\\nEMP_516,10,2,4,160\\r\\nEMP_517,5,2,4,100\\r\\nEMP_518,5,4,5,114\\r\\nEMP_519,3,3,6,86\\r\\nEMP_520,9,4,7,166\\r\\nEMP_521,4,7,8,126\\r\\nEMP_522,5,1,3,92\\r\\nEMP_523,4,6,9,122\\r\\nEMP_524,5,3,4,106\\r\\nEMP_525,7,10,13,190\\r\\nEMP_526,9,7,8,186\\r\\nEMP_527,7,10,12,188\\r\\nEMP_528,5,2,5,102\\r\\nEMP_529,10,2,3,158\\r\\nEMP_530,10,4,7,178\\r\\nEMP_531,7,1,4,118\\r\\nEMP_532,10,3,6,170\\r\\nEMP_533,5,9,12,158\\r\\nEMP_534,3,7,8,114\\r\\nEMP_535,7,7,9,164\\r\\nEMP_536,2,4,5,78\\r\\nEMP_537,9,2,3,146\\r\\nEMP_538,10,4,5,174\\r\\nEMP_539,10,6,8,192\\r\\nEMP_540,1,3,6,62\\r\\nEMP_541,6,1,4,106\\r\\nEMP_542,7,8,11,174\\r\\nEMP_543,8,5,7,160\\r\\nEMP_544,10,5,8,186\\r\\nEMP_545,9,4,6,164\\r\\nEMP_546,2,6,9,98\\r\\nEMP_547,10,3,6,170\\r\\nEMP_548,2,9,10,118\\r\\nEMP_549,5,5,7,124\\r\\nEMP_550,5,3,4,106\\r\\nEMP_551,6,1,2,102\\r\\nEMP_552,3,10,11,138\\r\\nEMP_553,8,6,8,168\\r\\nEMP_554,1,2,4,52\\r\\nEMP_555,6,3,6,122\\r\\nEMP_556,4,1,2,78\\r\\nEMP_557,1,9,12,110\\r\\nEMP_558,7,8,9,170\\r\\nEMP_559,9,2,4,148\\r\\nEMP_560,4,8,10,136\\r\\nEMP_561,4,9,11,144\\r\\nEMP_562,6,1,2,102\\r\\nEMP_563,3,5,7,100\\r\\nEMP_564,6,8,9,158\\r\\nEMP_565,7,2,5,126\\r\\nEMP_566,10,4,5,174\\r\\nEMP_567,10,7,10,202\\r\\nEMP_568,3,3,4,82\\r\\nEMP_569,7,5,8,150\\r\\nEMP_570,3,8,10,124\\r\\nEMP_571,2,10,13,130\\r\\nEMP_572,10,3,5,168\\r\\nEMP_573,4,4,6,104\\r\\nEMP_574,8,9,12,194\\r\\nEMP_575,9,7,8,186\\r\\nEMP_576,7,1,2,114\\r\\nEMP_577,1,4,5,66\\r\\nEMP_578,3,4,5,90\\r\\nEMP_579,9,9,10,202\\r\\nEMP_580,1,6,8,84\\r\\nEMP_581,9,9,10,202\\r\\nEMP_582,8,6,8,168\\r\\nEMP_583,1,6,8,84\\r\\nEMP_584,6,5,7,136\\r\\nEMP_585,5,5,8,126\\r\\nEMP_586,6,2,5,114\\r\\nEMP_587,10,8,10,208\\r\\nEMP_588,5,8,11,150\\r\\nEMP_589,6,1,2,102\\r\\nEMP_590,5,8,9,146\\r\\nEMP_591,5,5,7,124\\r\\nEMP_592,4,2,3,86\\r\\nEMP_593,3,2,4,76\\r\\nEMP_594,3,6,8,108\\r\\nEMP_595,4,9,10,142\\r\\nEMP_596,9,1,4,142\\r\\nEMP_597,2,6,7,94\\r\\nEMP_598,9,9,10,202\\r\\nEMP_599,1,8,10,100\\r\\nEMP_600,1,6,8,84\\r\\nEMP_601,5,3,5,108\\r\\nEMP_602,6,8,10,160\\r\\nEMP_603,6,9,12,170\\r\\nEMP_604,3,1,4,70\\r\\nEMP_605,7,9,12,182\\r\\nEMP_606,9,6,8,180\\r\\nEMP_607,10,6,8,192\\r\\nEMP_608,8,4,6,152\\r\\nEMP_609,6,1,4,106\\r\\nEMP_610,8,10,12,200\\r\\nEMP_611,5,8,9,146\\r\\nEMP_612,8,2,3,134\\r\\nEMP_613,10,1,3,152\\r\\nEMP_614,4,2,3,86\\r\\nEMP_615,10,1,2,150\\r\\nEMP_616,8,1,4,130\\r\\nEMP_617,10,9,11,216\\r\\nEMP_618,2,1,3,56\\r\\nEMP_619,5,4,7,118\\r\\nEMP_620,9,10,11,210\\r\\nEMP_621,4,6,7,118\\r\\nEMP_622,6,7,9,152\\r\\nEMP_623,1,2,3,50\\r\\nEMP_624,9,6,9,182\\r\\nEMP_625,1,7,10,94\\r\\nEMP_626,5,10,12,164\\r\\nEMP_627,4,10,13,154\\r\\nEMP_628,3,2,5,78\\r\\nEMP_629,6,2,4,112\\r\\nEMP_630,2,10,13,130\\r\\nEMP_631,3,7,10,118\\r\\nEMP_632,5,1,4,94\\r\\nEMP_633,9,8,9,194\\r\\nEMP_634,2,3,5,72\\r\\nEMP_635,10,6,8,192\\r\\nEMP_636,8,9,11,192\\r\\nEMP_637,2,6,7,94\\r\\nEMP_638,5,9,10,154\\r\\nEMP_639,7,7,9,164\\r\\nEMP_640,8,9,10,190\\r\\nEMP_641,1,2,4,52\\r\\nEMP_642,6,8,9,158\\r\\nEMP_643,1,8,11,102\\r\\nEMP_644,2,2,5,66\\r\\nEMP_645,1,4,6,68\\r\\nEMP_646,5,7,8,138\\r\\nEMP_647,10,4,5,174\\r\\nEMP_648,9,4,7,166\\r\\nEMP_649,6,6,9,146\\r\\nEMP_650,1,10,11,114\\r\\nEMP_651,1,6,7,82\\r\\nEMP_652,2,10,11,126\\r\\nEMP_653,9,3,4,154\\r\\nEMP_654,3,9,10,130\\r\\nEMP_655,1,10,11,114\\r\\nEMP_656,5,2,4,100\\r\\nEMP_657,7,6,7,154\\r\\nEMP_658,6,7,10,154\\r\\nEMP_659,1,9,11,108\\r\\nEMP_660,5,3,4,106\\r\\nEMP_661,5,10,13,166\\r\\nEMP_662,6,3,5,120\\r\\nEMP_663,3,7,10,118\\r\\nEMP_664,5,4,5,114\\r\\nEMP_665,7,8,9,170\\r\\nEMP_666,5,7,8,138\\r\\nEMP_667,5,5,6,122\\r\\nEMP_668,5,7,9,140\\r\\nEMP_669,10,3,5,168\\r\\nEMP_670,10,2,5,162\\r\\nEMP_671,3,6,7,106\\r\\nEMP_672,1,2,5,54\\r\\nEMP_673,5,3,5,108\\r\\nEMP_674,9,6,7,178\\r\\nEMP_675,1,5,6,74\\r\\nEMP_676,3,8,10,124\\r\\nEMP_677,4,9,11,144\\r\\nEMP_678,1,3,5,60\\r\\nEMP_679,1,10,12,116\\r\\nEMP_680,8,3,5,144\\r\\nEMP_681,2,3,4,70\\r\\nEMP_682,8,6,8,168\\r\\nEMP_683,7,1,2,114\\r\\nEMP_684,10,7,8,198\\r\\nEMP_685,10,1,3,152\\r\\nEMP_686,2,5,7,88\\r\\nEMP_687,6,10,11,174\\r\\nEMP_688,6,8,10,160\\r\\nEMP_689,3,4,6,92\\r\\nEMP_690,2,5,7,88\\r\\nEMP_691,1,4,7,70\\r\\nEMP_692,6,4,5,126\\r\\nEMP_693,5,8,11,150\\r\\nEMP_694,9,2,4,148\\r\\nEMP_695,1,1,4,46\\r\\nEMP_696,7,3,5,132\\r\\nEMP_697,5,9,12,158\\r\\nEMP_698,5,4,6,116\\r\\nEMP_699,2,10,13,130\\r\\nEMP_700,3,5,8,102\\r\\nEMP_701,7,2,5,126\\r\\nEMP_702,6,4,5,126\\r\\nEMP_703,2,2,5,66\\r\\nEMP_704,6,2,3,110\\r\\nEMP_705,2,4,6,80\\r\\nEMP_706,2,6,9,98\\r\\nEMP_707,2,7,9,104\\r\\nEMP_708,3,10,12,140\\r\\nEMP_709,2,3,6,74\\r\\nEMP_710,4,3,4,94\\r\\nEMP_711,9,10,13,214\\r\\nEMP_712,6,6,8,144\\r\\nEMP_713,1,3,5,60\\r\\nEMP_714,8,2,5,138\\r\\nEMP_715,7,8,9,170\\r\\nEMP_716,10,5,6,182\\r\\nEMP_717,3,1,3,68\\r\\nEMP_718,1,3,5,60\\r\\nEMP_719,5,10,11,162\\r\\nEMP_720,4,8,11,138\\r\\nEMP_721,10,4,6,176\\r\\nEMP_722,8,7,8,174\\r\\nEMP_723,1,10,12,116\\r\\nEMP_724,10,2,5,162\\r\\nEMP_725,1,7,8,90\\r\\nEMP_726,4,5,7,112\\r\\nEMP_727,8,5,8,162\\r\\nEMP_728,5,6,8,132\\r\\nEMP_729,2,9,12,122\\r\\nEMP_730,6,6,9,146\\r\\nEMP_731,5,8,9,146\\r\\nEMP_732,2,7,10,106\\r\\nEMP_733,3,9,11,132\\r\\nEMP_734,9,4,7,166\\r\\nEMP_735,7,2,5,126\\r\\nEMP_736,7,7,8,162\\r\\nEMP_737,6,6,9,146\\r\\nEMP_738,8,1,4,130\\r\\nEMP_739,4,9,11,144\\r\\nEMP_740,8,9,10,190\\r\\nEMP_741,4,2,3,86\\r\\nEMP_742,8,3,4,142\\r\\nEMP_743,9,5,8,174\\r\\nEMP_744,3,5,6,98\\r\\nEMP_745,3,1,4,70\\r\\nEMP_746,2,8,11,114\\r\\nEMP_747,10,8,10,208\\r\\nEMP_748,3,4,6,92\\r\\nEMP_749,3,7,9,116\\r\\nEMP_750,5,10,12,164\\r\\nEMP_751,5,3,5,108\\r\\nEMP_752,2,6,9,98\\r\\nEMP_753,10,10,13,226\\r\\nEMP_754,6,10,11,174\\r\\nEMP_755,5,9,12,158\\r\\nEMP_756,6,1,4,106\\r\\nEMP_757,1,5,7,76\\r\\nEMP_758,5,4,7,118\\r\\nEMP_759,9,8,10,196\\r\\nEMP_760,10,1,2,150\\r\\nEMP_761,2,9,10,118\\r\\nEMP_762,1,6,9,86\\r\\nEMP_763,10,4,5,174\\r\\nEMP_764,9,9,12,206\\r\\nEMP_765,10,5,6,182\\r\\nEMP_766,9,5,7,172\\r\\nEMP_767,9,5,7,172\\r\\nEMP_768,6,1,3,104\\r\\nEMP_769,8,1,3,128\\r\\nEMP_770,1,8,11,102\\r\\nEMP_771,10,8,9,206\\r\\nEMP_772,4,6,9,122\\r\\nEMP_773,1,4,6,68\\r\\nEMP_774,8,2,5,138\\r\\nEMP_775,1,2,3,50\\r\\nEMP_776,3,9,12,134\\r\\nEMP_777,4,5,6,110\\r\\nEMP_778,8,4,7,154\\r\\nEMP_779,6,10,11,174\\r\\nEMP_780,10,1,2,150\\r\\nEMP_781,7,7,9,164\\r\\nEMP_782,8,3,4,142\\r\\nEMP_783,2,6,8,96\\r\\nEMP_784,10,5,7,184\\r\\nEMP_785,8,5,7,160\\r\\nEMP_786,3,5,8,102\\r\\nEMP_787,7,1,4,118\\r\\nEMP_788,3,1,4,70\\r\\nEMP_789,7,3,6,134\\r\\nEMP_790,2,10,11,126\\r\\nEMP_791,10,4,5,174\\r\\nEMP_792,6,5,8,138\\r\\nEMP_793,3,2,3,74\\r\\nEMP_794,3,8,9,122\\r\\nEMP_795,9,2,4,148\\r\\nEMP_796,7,9,11,180\\r\\nEMP_797,5,2,4,100\\r\\nEMP_798,10,9,11,216\\r\\nEMP_799,7,7,8,162\\r\\nEMP_800,9,8,11,198\\r\\nEMP_801,1,2,3,50\\r\\nEMP_802,7,7,8,162\\r\\nEMP_803,6,6,7,142\\r\\nEMP_804,10,4,6,176\\r\\nEMP_805,9,7,9,188\\r\\nEMP_806,1,4,6,68\\r\\nEMP_807,4,2,5,90\\r\\nEMP_808,9,10,11,210\\r\\nEMP_809,4,7,10,130\\r\\nEMP_810,10,8,10,208\\r\\nEMP_811,3,2,5,78\\r\\nEMP_812,9,5,6,170\\r\\nEMP_813,2,1,2,54\\r\\nEMP_814,4,7,9,128\\r\\nEMP_815,6,8,10,160\\r\\nEMP_816,2,6,9,98\\r\\nEMP_817,8,5,7,160\\r\\nEMP_818,8,6,8,168\\r\\nEMP_819,1,2,3,50\\r\\nEMP_820,3,1,3,68\\r\\nEMP_821,10,7,9,200\\r\\nEMP_822,9,7,8,186\\r\\nEMP_823,5,10,11,162\\r\\nEMP_824,6,10,13,178\\r\\nEMP_825,4,2,4,88\\r\\nEMP_826,10,2,3,158\\r\\nEMP_827,2,1,4,58\\r\\nEMP_828,8,10,13,202\\r\\nEMP_829,6,8,10,160\\r\\nEMP_830,5,8,10,148\\r\\nEMP_831,9,1,4,142\\r\\nEMP_832,1,8,9,98\\r\\nEMP_833,5,9,12,158\\r\\nEMP_834,6,4,6,128\\r\\nEMP_835,5,1,2,90\\r\\nEMP_836,6,1,2,102\\r\\nEMP_837,6,3,6,122\\r\\nEMP_838,7,5,7,148\\r\\nEMP_839,4,5,8,114\\r\\nEMP_840,8,9,12,194\\r\\nEMP_841,7,10,13,190\\r\\nEMP_842,9,2,3,146\\r\\nEMP_843,7,2,3,122\\r\\nEMP_844,3,6,8,108\\r\\nEMP_845,3,9,11,132\\r\\nEMP_846,8,1,4,130\\r\\nEMP_847,5,9,12,158\\r\\nEMP_848,4,9,12,146\\r\\nEMP_849,8,9,11,192\\r\\nEMP_850,6,5,6,134\\r\\nEMP_851,2,9,10,118\\r\\nEMP_852,4,4,7,106\\r\\nEMP_853,4,2,5,90\\r\\nEMP_854,6,6,9,146\\r\\nEMP_855,6,4,7,130\\r\\nEMP_856,1,6,8,84\\r\\nEMP_857,8,3,4,142\\r\\nEMP_858,6,6,9,146\\r\\nEMP_859,3,2,4,76\\r\\nEMP_860,9,2,5,150\\r\\nEMP_861,2,9,12,122\\r\\nEMP_862,8,7,8,174\\r\\nEMP_863,10,3,6,170\\r\\nEMP_864,3,1,2,66\\r\\nEMP_865,5,8,9,146\\r\\nEMP_866,6,6,7,142\\r\\nEMP_867,10,7,9,200\\r\\nEMP_868,6,9,11,168\\r\\nEMP_869,4,5,6,110\\r\\nEMP_870,3,1,4,70\\r\\nEMP_871,4,10,11,150\\r\\nEMP_872,1,7,10,94\\r\\nEMP_873,4,5,6,110\\r\\nEMP_874,1,3,6,62\\r\\nEMP_875,1,9,11,108\\r\\nEMP_876,10,1,4,154\\r\\nEMP_877,6,1,2,102\\r\\nEMP_878,5,1,3,92\\r\\nEMP_879,4,3,6,98\\r\\nEMP_880,3,6,9,110\\r\\nEMP_881,1,10,13,118\\r\\nEMP_882,6,3,6,122\\r\\nEMP_883,2,8,11,114\\r\\nEMP_884,8,10,12,200\\r\\nEMP_885,10,2,4,160\\r\\nEMP_886,5,9,11,156\\r\\nEMP_887,7,3,5,132\\r\\nEMP_888,10,5,6,182\\r\\nEMP_889,2,10,12,128\\r\\nEMP_890,8,8,11,186\\r\\nEMP_891,2,2,5,66\\r\\nEMP_892,4,6,8,120\\r\\nEMP_893,1,5,8,78\\r\\nEMP_894,5,10,12,164\\r\\nEMP_895,9,9,12,206\\r\\nEMP_896,1,5,6,74\\r\\nEMP_897,9,2,3,146\\r\\nEMP_898,8,5,7,160\\r\\nEMP_899,6,4,6,128\\r\\nEMP_900,7,7,9,164\\r\\nEMP_901,3,6,9,110\\r\\nEMP_902,1,2,4,52\\r\\nEMP_903,5,5,6,122\\r\\nEMP_904,2,7,10,106\\r\\nEMP_905,5,7,9,140\\r\\nEMP_906,8,5,8,162\\r\\nEMP_907,9,9,12,206\\r\\nEMP_908,2,4,6,80\\r\\nEMP_909,3,3,6,86\\r\\nEMP_910,3,4,5,90\\r\\nEMP_911,1,5,6,74\\r\\nEMP_912,8,6,9,170\\r\\nEMP_913,6,3,5,120\\r\\nEMP_914,8,2,5,138\\r\\nEMP_915,9,4,5,162\\r\\nEMP_916,5,5,8,126\\r\\nEMP_917,3,4,7,94\\r\\nEMP_918,5,3,4,106\\r\\nEMP_919,5,8,11,150\\r\\nEMP_920,5,10,13,166\\r\\nEMP_921,3,4,6,92\\r\\nEMP_922,10,2,4,160\\r\\nEMP_923,4,2,3,86\\r\\nEMP_924,9,1,2,138\\r\\nEMP_925,10,4,5,174\\r\\nEMP_926,9,10,12,212\\r\\nEMP_927,2,9,10,118\\r\\nEMP_928,8,7,8,174\\r\\nEMP_929,8,10,11,198\\r\\nEMP_930,7,7,9,164\\r\\nEMP_931,8,7,10,178\\r\\nEMP_932,3,8,9,122\\r\\nEMP_933,6,1,4,106\\r\\nEMP_934,1,10,11,114\\r\\nEMP_935,7,10,13,190\\r\\nEMP_936,1,8,10,100\\r\\nEMP_937,9,4,6,164\\r\\nEMP_938,1,4,5,66\\r\\nEMP_939,1,4,7,70\\r\\nEMP_940,7,6,8,156\\r\\nEMP_941,2,7,8,102\\r\\nEMP_942,5,6,7,130\\r\\nEMP_943,8,1,3,128\\r\\nEMP_944,8,8,10,184\\r\\nEMP_945,3,10,11,138\\r\\nEMP_946,7,7,10,166\\r\\nEMP_947,3,6,9,110\\r\\nEMP_948,6,6,9,146\\r\\nEMP_949,6,5,6,134\\r\\nEMP_950,3,6,8,108\\r\\nEMP_951,7,9,10,178\\r\\nEMP_952,3,10,12,140\\r\\nEMP_953,8,9,12,194\\r\\nEMP_954,10,10,13,226\\r\\nEMP_955,4,8,10,136\\r\\nEMP_956,1,10,12,116\\r\\nEMP_957,4,9,10,142\\r\\nEMP_958,7,10,13,190\\r\\nEMP_959,4,8,9,134\\r\\nEMP_960,6,8,9,158\\r\\nEMP_961,9,1,2,138\\r\\nEMP_962,1,10,13,118\\r\\nEMP_963,5,5,6,122\\r\\nEMP_964,7,4,5,138\\r\\nEMP_965,1,2,3,50\\r\\nEMP_966,4,8,9,134\\r\\nEMP_967,6,3,4,118\\r\\nEMP_968,2,4,5,78\\r\\nEMP_969,10,7,10,202\\r\\nEMP_970,5,10,11,162\\r\\nEMP_971,10,9,11,216\\r\\nEMP_972,1,2,3,50\\r\\nEMP_973,6,3,4,118\\r\\nEMP_974,6,4,7,130\\r\\nEMP_975,4,10,13,154\\r\\nEMP_976,8,1,3,128\\r\\nEMP_977,4,7,9,128\\r\\nEMP_978,8,2,5,138\\r\\nEMP_979,8,5,8,162\\r\\nEMP_980,5,1,2,90\\r\\nEMP_981,4,3,6,98\\r\\nEMP_982,2,2,4,64\\r\\nEMP_983,3,1,2,66\\r\\nEMP_984,3,7,9,116\\r\\nEMP_985,4,5,6,110\\r\\nEMP_986,4,1,4,82\\r\\nEMP_987,10,6,8,192\\r\\nEMP_988,5,5,6,122\\r\\nEMP_989,4,3,4,94\\r\\nEMP_990,10,7,10,202\\r\\nEMP_991,8,10,13,202\\r\\nEMP_992,6,9,12,170\\r\\nEMP_993,6,9,11,168\\r\\nEMP_994,8,9,10,190\\r\\nEMP_995,7,2,5,126\\r\\nEMP_996,10,3,5,168\\r\\nEMP_997,10,7,9,200\\r\\nEMP_998,8,5,7,160\\r\\nEMP_999,2,2,5,66\\r\\nEMP_1000,9,3,6,158\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required modeules and dataframe\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "data = pd.read_csv(\"bonus prediction nn.csv\")\n",
        "df = pd.DataFrame(data)\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "rPEX-WCHA0Qb",
        "outputId": "4fc4f84d-ff2f-4066-a6ec-05625202351c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  employee_id  performance  years_of_experience  projects_completed  bonus\n",
              "0     EMP_001            7                    1                   3    116\n",
              "1     EMP_002            4                    8                  10    136\n",
              "2     EMP_003            8                    4                   5    150"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c7da1fd-846c-41ea-95e4-6e56ca2e62fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employee_id</th>\n",
              "      <th>performance</th>\n",
              "      <th>years_of_experience</th>\n",
              "      <th>projects_completed</th>\n",
              "      <th>bonus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EMP_001</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EMP_002</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EMP_003</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c7da1fd-846c-41ea-95e4-6e56ca2e62fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c7da1fd-846c-41ea-95e4-6e56ca2e62fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c7da1fd-846c-41ea-95e4-6e56ca2e62fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"employee_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"EMP_522\",\n          \"EMP_738\",\n          \"EMP_741\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"performance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"years_of_experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7,\n          8,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"projects_completed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2,\n        \"max\": 13,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          13,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bonus\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42,\n        \"min\": 42,\n        \"max\": 226,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          78,\n          162,\n          42\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "5xb_XgJJCwL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz67TVvE1gHW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df[[\"performance\",\"years_of_experience\",\"projects_completed\"]].values\n",
        "y = df[[\"bonus\"]].values\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
        "\n",
        "x_train_tensor = torch.tensor(x_train,dtype=torch.float32)\n",
        "x_test_tensor = torch.tensor(x_test,dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train,dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test,dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh_xGROjEJlt",
        "outputId": "478c29ae-ed9e-4754-d43a-b3e924cd7274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Neural Network"
      ],
      "metadata": {
        "id": "5OiGts0DEbDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Seed for reproducibility\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDQm7dc7EXwf",
        "outputId": "c0efe363-21b6-45fa-8aab-c0ecc53d6c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7808c454bed0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BestPredictor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(nn.Linear(3,1))   # provides three input / one output neuron\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.network(x)"
      ],
      "metadata": {
        "id": "lI17zKZwE99r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BestPredictor()\n",
        "optimizer = optim.SGD(model.parameters(),lr= 0.005)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "k0haCFJ8GUwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # forward\n",
        "  prediction = model(x_train_tensor)\n",
        "  loss = criterion(prediction,y_train_tensor)\n",
        "\n",
        "  #backpropagation\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  #updata weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # print the loss at every 100 iteration\n",
        "  if (epoch+1) % 100 == 0:\n",
        "    print(f\"epoch [{epoch+1} / {epochs}] ,loss {loss.item():0.2f} \")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o28g6K1G-XF",
        "outputId": "9a97a792-1b94-4da7-8861-2383bf534665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [100 / 5000] ,loss 20.22 \n",
            "epoch [200 / 5000] ,loss 17.51 \n",
            "epoch [300 / 5000] ,loss 15.31 \n",
            "epoch [400 / 5000] ,loss 13.45 \n",
            "epoch [500 / 5000] ,loss 11.83 \n",
            "epoch [600 / 5000] ,loss 10.41 \n",
            "epoch [700 / 5000] ,loss 9.16 \n",
            "epoch [800 / 5000] ,loss 8.07 \n",
            "epoch [900 / 5000] ,loss 7.10 \n",
            "epoch [1000 / 5000] ,loss 6.25 \n",
            "epoch [1100 / 5000] ,loss 5.51 \n",
            "epoch [1200 / 5000] ,loss 4.85 \n",
            "epoch [1300 / 5000] ,loss 4.27 \n",
            "epoch [1400 / 5000] ,loss 3.76 \n",
            "epoch [1500 / 5000] ,loss 3.31 \n",
            "epoch [1600 / 5000] ,loss 2.91 \n",
            "epoch [1700 / 5000] ,loss 2.56 \n",
            "epoch [1800 / 5000] ,loss 2.26 \n",
            "epoch [1900 / 5000] ,loss 1.99 \n",
            "epoch [2000 / 5000] ,loss 1.75 \n",
            "epoch [2100 / 5000] ,loss 1.54 \n",
            "epoch [2200 / 5000] ,loss 1.36 \n",
            "epoch [2300 / 5000] ,loss 1.19 \n",
            "epoch [2400 / 5000] ,loss 1.05 \n",
            "epoch [2500 / 5000] ,loss 0.93 \n",
            "epoch [2600 / 5000] ,loss 0.82 \n",
            "epoch [2700 / 5000] ,loss 0.72 \n",
            "epoch [2800 / 5000] ,loss 0.63 \n",
            "epoch [2900 / 5000] ,loss 0.56 \n",
            "epoch [3000 / 5000] ,loss 0.49 \n",
            "epoch [3100 / 5000] ,loss 0.43 \n",
            "epoch [3200 / 5000] ,loss 0.38 \n",
            "epoch [3300 / 5000] ,loss 0.33 \n",
            "epoch [3400 / 5000] ,loss 0.29 \n",
            "epoch [3500 / 5000] ,loss 0.26 \n",
            "epoch [3600 / 5000] ,loss 0.23 \n",
            "epoch [3700 / 5000] ,loss 0.20 \n",
            "epoch [3800 / 5000] ,loss 0.18 \n",
            "epoch [3900 / 5000] ,loss 0.16 \n",
            "epoch [4000 / 5000] ,loss 0.14 \n",
            "epoch [4100 / 5000] ,loss 0.12 \n",
            "epoch [4200 / 5000] ,loss 0.11 \n",
            "epoch [4300 / 5000] ,loss 0.09 \n",
            "epoch [4400 / 5000] ,loss 0.08 \n",
            "epoch [4500 / 5000] ,loss 0.07 \n",
            "epoch [4600 / 5000] ,loss 0.06 \n",
            "epoch [4700 / 5000] ,loss 0.06 \n",
            "epoch [4800 / 5000] ,loss 0.05 \n",
            "epoch [4900 / 5000] ,loss 0.04 \n",
            "epoch [5000 / 5000] ,loss 0.04 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch to evaluation mode (important for models with dropout/batch norm layers)\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient calculations for evaluation to save memory\n",
        "with torch.no_grad():\n",
        "  test_prediction = model(x_test_tensor)\n",
        "  test_loss = criterion(test_prediction,y_test_tensor)\n",
        "\n",
        "\n",
        "print(f\"Test loss is the {test_loss.item():0.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWCC76KdI_JG",
        "outputId": "bae9f0df-66bb-44ff-a869-dab74f2a02c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss is the 0.04\n"
          ]
        }
      ]
    }
  ]
}